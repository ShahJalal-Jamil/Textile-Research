{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShahJalal-Jamil/Textile-Research/blob/main/My_Code_Textile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Q01W2aGHCL"
      },
      "source": [
        "**Step-1:** DataSet Import and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaT5DwVmFeRT",
        "outputId": "5713d84f-335b-40d3-9448-828426ce70c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Textile-Research'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18/18), 115.88 KiB | 6.82 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "     Fabric Name  ST    MS  SPI  NN    FT  GSM    T_S  Tex     El  \\\n",
            "0              0   5  3500   10   9  0.18  160   4.75   30  15.00   \n",
            "1              0   6  3800   10   9  0.21  160   5.15   30  15.00   \n",
            "2              0   5  3600   10   9  0.22  160   5.15   30  15.00   \n",
            "3              0   4  3500   10   9  0.22  160   5.15   30  17.00   \n",
            "4              0   5  3500   10   9  0.21  160   5.15   30  15.00   \n",
            "..           ...  ..   ...  ...  ..   ...  ...    ...  ...    ...   \n",
            "995            7   6  3000   10  16  0.62  310  11.95  100  26.48   \n",
            "996            7   5  2800   10  16  0.62  310  10.89  100  26.48   \n",
            "997            7   7  3000   10  16  0.62  310  12.31  100  26.11   \n",
            "998            7   5  2500   10  16  0.62  310  11.70  100  26.48   \n",
            "999            7   4  2800   10  16  0.62  310  11.98  100  24.11   \n",
            "\n",
            "     No of B._hr  Class (Y/N)  \n",
            "0              2            1  \n",
            "1              3            1  \n",
            "2              1            0  \n",
            "3              1            0  \n",
            "4              1            0  \n",
            "..           ...          ...  \n",
            "995            1            0  \n",
            "996            1            0  \n",
            "997            3            1  \n",
            "998            0            0  \n",
            "999            0            0  \n",
            "\n",
            "[1000 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# Dataset load and Pre-processing\n",
        "!git clone https://github.com/ShahJalal-Jamil/Textile-Research.git\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(r'/content/Textile-Research/data_textile.xlsx')\n",
        "df = df.replace('Jersey', 0, regex=True)\n",
        "df = df.replace('DLacoste', 1, regex=True)\n",
        "df = df.replace('Fleece', 2, regex=True)\n",
        "df = df.replace('Lacoste', 3, regex=True)\n",
        "df = df.replace('Pique', 4, regex=True)\n",
        "df = df.replace('Plain', 5, regex=True)\n",
        "df = df.replace('RDenim', 6, regex=True)\n",
        "df = df.replace('SDenim', 7, regex=True)\n",
        "df = df.replace('Twill', 8, regex=True)\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfg-QJVcF_Qa",
        "outputId": "946c8e03-0836-42b3-c186-47f5efaf1352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fabric Name\n",
            "9\n",
            "ST\n",
            "4\n",
            "MS\n",
            "11\n",
            "SPI\n",
            "3\n",
            "NN\n",
            "5\n",
            "GSM\n",
            "66\n",
            "T_S\n",
            "287\n",
            "Tex\n",
            "5\n",
            "El\n",
            "86\n"
          ]
        }
      ],
      "source": [
        "# Data Normalization\n",
        "c = df.columns\n",
        "for i in range(0,10):\n",
        "    if i!= 5:\n",
        "        column_name = c[i]\n",
        "        print(column_name)\n",
        "        l = df[column_name].unique()\n",
        "        #print (l)\n",
        "        print(l.size)\n",
        "        max_value = max(l)\n",
        "        for j in range(0,l.size):\n",
        "            df[column_name] = df[column_name].replace(l[j], l[j]/max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUATw0sYGEog",
        "outputId": "73e51217-f96c-4664-b873-0f9ba95706ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "(1000, 10)\n",
            "[[0.         0.71428571 0.875      ... 0.33928571 0.3        0.56646526]\n",
            " [0.         0.85714286 0.95       ... 0.36785714 0.3        0.56646526]\n",
            " [0.         0.71428571 0.9        ... 0.36785714 0.3        0.56646526]\n",
            " ...\n",
            " [0.875      1.         0.75       ... 0.87928571 1.         0.98602719]\n",
            " [0.875      0.71428571 0.625      ... 0.83571429 1.         1.        ]\n",
            " [0.875      0.57142857 0.7        ... 0.85571429 1.         0.91049849]]\n"
          ]
        }
      ],
      "source": [
        "# Data Assigning into X and Y for Traning and Testing\n",
        "# X = df.drop('target', axis=1)  # Features\n",
        "# y = df['target']  # Target variable\n",
        "\n",
        "\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "print(X_new.shape)\n",
        "print(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSPZkh27SIkg"
      },
      "source": [
        "**Step2:** Applying Decion Tree Classifier along with K-fold Cross Validation and Reuslts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbNpOB5EDb7l",
        "outputId": "15daca2a-f32d-4c44-c32d-50b6839eccfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8480\n",
            "Recall: 0.8346\n",
            "F1 Score: 0.8413\n",
            "Confusion Matrix:\n",
            "[[ 54  19]\n",
            " [ 21 106]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8852\n",
            "Recall: 0.8182\n",
            "F1 Score: 0.8504\n",
            "Confusion Matrix:\n",
            "[[ 54  14]\n",
            " [ 24 108]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.9231\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.8571\n",
            "Confusion Matrix:\n",
            "[[ 56   9]\n",
            " [ 27 108]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.7850\n",
            "Precision: 0.8320\n",
            "Recall: 0.8254\n",
            "F1 Score: 0.8287\n",
            "Confusion Matrix:\n",
            "[[ 53  21]\n",
            " [ 22 104]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[52 19]\n",
            " [32 97]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7920\n",
            "Overall Precision: 0.8645\n",
            "Overall Recall: 0.8059\n",
            "Overall F1 Score: 0.8341\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[269  82]\n",
            " [126 523]]\n"
          ]
        }
      ],
      "source": [
        "# Decion Tree and Results with cross validation\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Initialize Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state= 42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig4WmyOHEnms",
        "outputId": "8e3f9d33-c944-46c1-9074-5fd8f6734973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8020\n",
            "Overall Precision: 0.8551\n",
            "Overall Recall: 0.8367\n",
            "Overall F1 Score: 0.8458\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[259  92]\n",
            " [106 543]]\n"
          ]
        }
      ],
      "source": [
        "# Decion Tree and Results with LEAVE ONE OUT Method\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Data Assigning into X and Y for Traning and Testing\n",
        "# X = df.drop('target', axis=1)  # Features\n",
        "# y = df['target']  # Target variable\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "\n",
        "# Initialize Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUXb1MJcKWM"
      },
      "source": [
        "2. Naibe Bayes Classifier along with K-fold Cross Validation and Reuslts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHWyeVsadIc0",
        "outputId": "ffdf5c4e-c8c0-4930-abb0-b34eae7fa70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 37  36]\n",
            " [ 17 110]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 28  40]\n",
            " [ 13 119]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 26  39]\n",
            " [ 15 120]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 43  31]\n",
            " [ 19 107]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7450\n",
            "Precision: 0.8362\n",
            "Recall: 0.7519\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 25  46]\n",
            " [ 19 110]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7250\n",
            "Overall Precision: 0.7467\n",
            "Overall Recall: 0.8721\n",
            "Overall F1 Score: 0.8045\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[159 192]\n",
            " [ 83 566]]\n"
          ]
        }
      ],
      "source": [
        "# Decion Tree and Results with k-fold Cross Validation Method\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Naive Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwYwV4L0ck-x",
        "outputId": "8567269c-44bf-4db2-842d-93b54921d6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7260\n",
            "Overall Precision: 0.7477\n",
            "Overall Recall: 0.8721\n",
            "Overall F1 Score: 0.8051\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[160 191]\n",
            " [ 83 566]]\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes and Results with LEAVE ONE OUT Method\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Naive Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-LPio6io4TB"
      },
      "source": [
        "3. K-Nearest Neighbor along with Cross Validation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw6kdoAFpA3S",
        "outputId": "d8b067e6-b555-4666-be5c-49bc29897903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 11):\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.8143\n",
            "Recall: 0.8261\n",
            "F1 Score: 0.8201\n",
            "Confusion Matrix:\n",
            "[[18 13]\n",
            " [12 57]]\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8065\n",
            "Recall: 0.8621\n",
            "F1 Score: 0.8333\n",
            "Confusion Matrix:\n",
            "[[30 12]\n",
            " [ 8 50]]\n",
            "\n",
            "Metrics (Fold 31):\n",
            "Accuracy: 0.8300\n",
            "Precision: 0.8750\n",
            "Recall: 0.8615\n",
            "F1 Score: 0.8682\n",
            "Confusion Matrix:\n",
            "[[27  8]\n",
            " [ 9 56]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8529\n",
            "Recall: 0.8657\n",
            "F1 Score: 0.8593\n",
            "Confusion Matrix:\n",
            "[[23 10]\n",
            " [ 9 58]]\n",
            "\n",
            "Metrics (Fold 51):\n",
            "Accuracy: 0.8900\n",
            "Precision: 0.9041\n",
            "Recall: 0.9429\n",
            "F1 Score: 0.9231\n",
            "Confusion Matrix:\n",
            "[[23  7]\n",
            " [ 4 66]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.7700\n",
            "Precision: 0.8182\n",
            "Recall: 0.8308\n",
            "F1 Score: 0.8244\n",
            "Confusion Matrix:\n",
            "[[23 12]\n",
            " [11 54]]\n",
            "\n",
            "Metrics (Fold 71):\n",
            "Accuracy: 0.7400\n",
            "Precision: 0.8393\n",
            "Recall: 0.7344\n",
            "F1 Score: 0.7833\n",
            "Confusion Matrix:\n",
            "[[27  9]\n",
            " [17 47]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8088\n",
            "Recall: 0.8871\n",
            "F1 Score: 0.8462\n",
            "Confusion Matrix:\n",
            "[[25 13]\n",
            " [ 7 55]]\n",
            "\n",
            "Metrics (Fold 91):\n",
            "Accuracy: 0.7700\n",
            "Precision: 0.7612\n",
            "Recall: 0.8793\n",
            "F1 Score: 0.8160\n",
            "Confusion Matrix:\n",
            "[[26 16]\n",
            " [ 7 51]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7800\n",
            "Precision: 0.8551\n",
            "Recall: 0.8310\n",
            "F1 Score: 0.8429\n",
            "Confusion Matrix:\n",
            "[[19 10]\n",
            " [12 59]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7940\n",
            "Overall Precision: 0.8341\n",
            "Overall Recall: 0.8521\n",
            "Overall F1 Score: 0.8430\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[241 110]\n",
            " [ 96 553]]\n"
          ]
        }
      ],
      "source": [
        "# .......K-NN k-fold Cross Validation Method and Results.................\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize K-Nearest Neighbors Classifier with k=3 (we can adjust the value of k)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAzZUA9fsEtg",
        "outputId": "7f1b9f29-9995-44d2-fd37-9a4cc03130cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8220\n",
            "Overall Precision: 0.8595\n",
            "Overall Recall: 0.8675\n",
            "Overall F1 Score: 0.8635\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[259  92]\n",
            " [ 86 563]]\n"
          ]
        }
      ],
      "source": [
        "# .........K-NN along with Leave-One-Out Method and Results............\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "\n",
        "# Initialize K-Nearest Neighbors Classifier with k=3 (you can adjust the value of k)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERqxP9mLtlR4"
      },
      "source": [
        "4. Schotasting Gradient Descent algorithm along with Validation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfr-gy_Mt7TZ",
        "outputId": "52910f52-2b35-4c43-ca65-549ae67534c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8372\n",
            "Recall: 0.8504\n",
            "F1 Score: 0.8438\n",
            "Confusion Matrix:\n",
            "[[ 52  21]\n",
            " [ 19 108]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.7600\n",
            "Precision: 0.9200\n",
            "Recall: 0.6970\n",
            "F1 Score: 0.7931\n",
            "Confusion Matrix:\n",
            "[[60  8]\n",
            " [40 92]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8150\n",
            "Precision: 0.8267\n",
            "Recall: 0.9185\n",
            "F1 Score: 0.8702\n",
            "Confusion Matrix:\n",
            "[[ 39  26]\n",
            " [ 11 124]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.7792\n",
            "Recall: 0.9524\n",
            "F1 Score: 0.8571\n",
            "Confusion Matrix:\n",
            "[[ 40  34]\n",
            " [  6 120]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7400\n",
            "Precision: 0.7333\n",
            "Recall: 0.9380\n",
            "F1 Score: 0.8231\n",
            "Confusion Matrix:\n",
            "[[ 27  44]\n",
            " [  8 121]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7830\n",
            "Overall Precision: 0.8095\n",
            "Overall Recall: 0.8706\n",
            "Overall F1 Score: 0.8389\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[218 133]\n",
            " [ 84 565]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# .........Schotasting Gradient Descent with K-fold Method and Results............\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "\n",
        "# Initialize Stochastic Gradient Descent Classifier\n",
        "sgd_classifier = SGDClassifier(loss='log', max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    sgd_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = sgd_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE0ndeUwwNkZ",
        "outputId": "9754f8b5-e8fd-44a2-fd91-baf5f38c1800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7420\n",
            "Overall Precision: 0.7556\n",
            "Overall Recall: 0.8906\n",
            "Overall F1 Score: 0.8175\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[164 187]\n",
            " [ 71 578]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# .........Schotasting Gradient Descent with Leave One Out CV and Results......\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Stochastic Gradient Descent Classifier\n",
        "sgd_classifier = SGDClassifier(loss='log', max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    sgd_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = sgd_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhcjyzSFxjr2"
      },
      "source": [
        "5. Random Forest along With Validation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HedVAx_kxuiv",
        "outputId": "5906f87f-87d0-4532-ad4e-e6566de8031f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.8321\n",
            "Recall: 0.8976\n",
            "F1 Score: 0.8636\n",
            "Confusion Matrix:\n",
            "[[ 50  23]\n",
            " [ 13 114]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.8750\n",
            "Recall: 0.8485\n",
            "F1 Score: 0.8615\n",
            "Confusion Matrix:\n",
            "[[ 52  16]\n",
            " [ 20 112]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8500\n",
            "Precision: 0.8889\n",
            "Recall: 0.8889\n",
            "F1 Score: 0.8889\n",
            "Confusion Matrix:\n",
            "[[ 50  15]\n",
            " [ 15 120]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.8516\n",
            "Recall: 0.8651\n",
            "F1 Score: 0.8583\n",
            "Confusion Matrix:\n",
            "[[ 55  19]\n",
            " [ 17 109]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7850\n",
            "Precision: 0.8308\n",
            "Recall: 0.8372\n",
            "F1 Score: 0.8340\n",
            "Confusion Matrix:\n",
            "[[ 49  22]\n",
            " [ 21 108]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8190\n",
            "Overall Precision: 0.8556\n",
            "Overall Recall: 0.8675\n",
            "Overall F1 Score: 0.8615\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[256  95]\n",
            " [ 86 563]]\n"
          ]
        }
      ],
      "source": [
        "#...........Random Forest with k-fold cross Validation and Results...........\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTNjAYKbzOXP",
        "outputId": "371e0776-95f6-4e68-8e22-63f135058c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8130\n",
            "Overall Precision: 0.8532\n",
            "Overall Recall: 0.8598\n",
            "Overall F1 Score: 0.8565\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[255  96]\n",
            " [ 91 558]]\n"
          ]
        }
      ],
      "source": [
        "#...........Random Forest with Leave One Out Validation and Results...........\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NrEfa7x11ID"
      },
      "source": [
        "6. Support Vector Machine along with Validation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG3ievAi1-Ai",
        "outputId": "dd6b8d36-5db2-4d72-afaf-dfe8a858e26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.7750\n",
            "Precision: 0.7808\n",
            "Recall: 0.8976\n",
            "F1 Score: 0.8352\n",
            "Confusion Matrix:\n",
            "[[ 41  32]\n",
            " [ 13 114]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.7550\n",
            "Precision: 0.7485\n",
            "Recall: 0.9470\n",
            "F1 Score: 0.8361\n",
            "Confusion Matrix:\n",
            "[[ 26  42]\n",
            " [  7 125]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.7600\n",
            "Precision: 0.7605\n",
            "Recall: 0.9407\n",
            "F1 Score: 0.8411\n",
            "Confusion Matrix:\n",
            "[[ 25  40]\n",
            " [  8 127]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.7905\n",
            "Recall: 0.9286\n",
            "F1 Score: 0.8540\n",
            "Confusion Matrix:\n",
            "[[ 43  31]\n",
            " [  9 117]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.6950\n",
            "Precision: 0.7073\n",
            "Recall: 0.8992\n",
            "F1 Score: 0.7918\n",
            "Confusion Matrix:\n",
            "[[ 23  48]\n",
            " [ 13 116]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7570\n",
            "Overall Precision: 0.7563\n",
            "Overall Recall: 0.9230\n",
            "Overall F1 Score: 0.8314\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[158 193]\n",
            " [ 50 599]]\n"
          ]
        }
      ],
      "source": [
        "#.............SVM with K-fold Cross Validation and Results............\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Support Vector Machine Classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1UMHkJa3W_i",
        "outputId": "11645e1f-6ee7-40c0-d86b-5a1e1ec6ec37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.7660\n",
            "Overall Precision: 0.7604\n",
            "Overall Recall: 0.9337\n",
            "Overall F1 Score: 0.8382\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[160 191]\n",
            " [ 43 606]]\n"
          ]
        }
      ],
      "source": [
        "#.............SVM with Leave-One-Out Method and Results.............\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize Support Vector Machine Classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P7F_SzF4ywz"
      },
      "source": [
        "7. Artificial Neural Network along with Cross Validation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7CF2m2dr47Z7",
        "outputId": "36bdf611-043c-4964-b50a-fb6538080f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 11):\n",
            "Accuracy: 0.8500\n",
            "Precision: 0.8750\n",
            "Recall: 0.9130\n",
            "F1 Score: 0.8936\n",
            "Confusion Matrix:\n",
            "[[22  9]\n",
            " [ 6 63]]\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.7794\n",
            "Recall: 0.9138\n",
            "F1 Score: 0.8413\n",
            "Confusion Matrix:\n",
            "[[27 15]\n",
            " [ 5 53]]\n",
            "\n",
            "Metrics (Fold 31):\n",
            "Accuracy: 0.8400\n",
            "Precision: 0.8889\n",
            "Recall: 0.8615\n",
            "F1 Score: 0.8750\n",
            "Confusion Matrix:\n",
            "[[28  7]\n",
            " [ 9 56]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8529\n",
            "Recall: 0.8657\n",
            "F1 Score: 0.8593\n",
            "Confusion Matrix:\n",
            "[[23 10]\n",
            " [ 9 58]]\n",
            "\n",
            "Metrics (Fold 51):\n",
            "Accuracy: 0.9300\n",
            "Precision: 0.9315\n",
            "Recall: 0.9714\n",
            "F1 Score: 0.9510\n",
            "Confusion Matrix:\n",
            "[[25  5]\n",
            " [ 2 68]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8500\n",
            "Precision: 0.8472\n",
            "Recall: 0.9385\n",
            "F1 Score: 0.8905\n",
            "Confusion Matrix:\n",
            "[[24 11]\n",
            " [ 4 61]]\n",
            "\n",
            "Metrics (Fold 71):\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.8485\n",
            "Recall: 0.8750\n",
            "F1 Score: 0.8615\n",
            "Confusion Matrix:\n",
            "[[26 10]\n",
            " [ 8 56]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7761\n",
            "Recall: 0.8387\n",
            "F1 Score: 0.8062\n",
            "Confusion Matrix:\n",
            "[[23 15]\n",
            " [10 52]]\n",
            "\n",
            "Metrics (Fold 91):\n",
            "Accuracy: 0.7800\n",
            "Precision: 0.7500\n",
            "Recall: 0.9310\n",
            "F1 Score: 0.8308\n",
            "Confusion Matrix:\n",
            "[[24 18]\n",
            " [ 4 54]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8400\n",
            "Recall: 0.8873\n",
            "F1 Score: 0.8630\n",
            "Confusion Matrix:\n",
            "[[17 12]\n",
            " [ 8 63]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8230\n",
            "Overall Precision: 0.8391\n",
            "Overall Recall: 0.8998\n",
            "Overall F1 Score: 0.8684\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[239 112]\n",
            " [ 65 584]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#..........ANN with k-fold cross validation and Results..........\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Standardize the features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize Artificial Neural Network Classifier\n",
        "ann_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    ann_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = ann_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n",
        "\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the heatmap\n",
        "sns.heatmap(overall_confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "\n",
        "# Set labels and title\n",
        "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy:.2%}')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Actual Label')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWujd5rh8Tki",
        "outputId": "d31edc34-d865-4c49-b591-77973621d50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8290\n",
            "Overall Precision: 0.8494\n",
            "Overall Recall: 0.8952\n",
            "Overall F1 Score: 0.8717\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[248 103]\n",
            " [ 68 581]]\n"
          ]
        }
      ],
      "source": [
        "#...........ANN with Leave one Out Method and Results\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Standardize the features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize Artificial Neural Network Classifier\n",
        "ann_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    ann_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = ann_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. AdaBoost Classifier along with Cross Validation and Results"
      ],
      "metadata": {
        "id": "vVgTvBfMhcLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ........AdaBoost Classier with k-fold Cross Validation and Results......\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize AdaBoost Classifier\n",
        "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = adaboost_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaboqMlKhnB2",
        "outputId": "4f1d54d4-f895-4a03-ee91-3728073218d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 11):\n",
            "Accuracy: 0.8300\n",
            "Precision: 0.8714\n",
            "Recall: 0.8841\n",
            "F1 Score: 0.8777\n",
            "Confusion Matrix:\n",
            "[[22  9]\n",
            " [ 8 61]]\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.8400\n",
            "Precision: 0.8387\n",
            "Recall: 0.8966\n",
            "F1 Score: 0.8667\n",
            "Confusion Matrix:\n",
            "[[32 10]\n",
            " [ 6 52]]\n",
            "\n",
            "Metrics (Fold 31):\n",
            "Accuracy: 0.8900\n",
            "Precision: 0.8971\n",
            "Recall: 0.9385\n",
            "F1 Score: 0.9173\n",
            "Confusion Matrix:\n",
            "[[28  7]\n",
            " [ 4 61]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8429\n",
            "Recall: 0.8806\n",
            "F1 Score: 0.8613\n",
            "Confusion Matrix:\n",
            "[[22 11]\n",
            " [ 8 59]]\n",
            "\n",
            "Metrics (Fold 51):\n",
            "Accuracy: 0.8700\n",
            "Precision: 0.8904\n",
            "Recall: 0.9286\n",
            "F1 Score: 0.9091\n",
            "Confusion Matrix:\n",
            "[[22  8]\n",
            " [ 5 65]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8358\n",
            "Recall: 0.8615\n",
            "F1 Score: 0.8485\n",
            "Confusion Matrix:\n",
            "[[24 11]\n",
            " [ 9 56]]\n",
            "\n",
            "Metrics (Fold 71):\n",
            "Accuracy: 0.7800\n",
            "Precision: 0.8387\n",
            "Recall: 0.8125\n",
            "F1 Score: 0.8254\n",
            "Confusion Matrix:\n",
            "[[26 10]\n",
            " [12 52]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.7400\n",
            "Precision: 0.7812\n",
            "Recall: 0.8065\n",
            "F1 Score: 0.7937\n",
            "Confusion Matrix:\n",
            "[[24 14]\n",
            " [12 50]]\n",
            "\n",
            "Metrics (Fold 91):\n",
            "Accuracy: 0.7700\n",
            "Precision: 0.7692\n",
            "Recall: 0.8621\n",
            "F1 Score: 0.8130\n",
            "Confusion Matrix:\n",
            "[[27 15]\n",
            " [ 8 50]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7900\n",
            "Precision: 0.8676\n",
            "Recall: 0.8310\n",
            "F1 Score: 0.8489\n",
            "Confusion Matrix:\n",
            "[[20  9]\n",
            " [12 59]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8120\n",
            "Overall Precision: 0.8445\n",
            "Overall Recall: 0.8706\n",
            "Overall F1 Score: 0.8574\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[247 104]\n",
            " [ 84 565]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#...........AdaBoos Classifier with Leave one oUt Method and Results.........\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Initialize AdaBoost Classifier\n",
        "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = adaboost_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "# Calculate overall metrics\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJS1j0bMiY03",
        "outputId": "d6e06769-97e6-41eb-c0f8-cf79e414be59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8230\n",
            "Overall Precision: 0.8533\n",
            "Overall Recall: 0.8783\n",
            "Overall F1 Score: 0.8656\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[253  98]\n",
            " [ 79 570]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Ensemble Method with K-fold Cross Validation"
      ],
      "metadata": {
        "id": "j9bKdlj-qF_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#...........Ensemble with K-fold Cross Validation and Results\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Define base classifiers for the ensemble\n",
        "ann_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC(probability=True, random_state=42)\n",
        "nb_classifier = GaussianNB()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "sgd_classifier = SGDClassifier(random_state=42)\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a majority voting ensemble classifier\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('ann', ann_classifier),\n",
        "        #('dt', dt_classifier),\n",
        "        ('svm', svm_classifier),\n",
        "        ('nb', nb_classifier),\n",
        "        ('knn', knn_classifier),\n",
        "        ('sgd', sgd_classifier),\n",
        "        ('rf', rf_classifier)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the ensemble model on the training data\n",
        "    ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = ensemble_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each fold\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each fold\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each fold\n",
        "    print(f\"\\nMetrics (Fold {len(all_predictions)//10 + 1}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n",
        "\n",
        "\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the heatmap\n",
        "sns.heatmap(overall_confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "\n",
        "# Set labels and title\n",
        "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy:.2%}')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Actual Label')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AGrVQwWlrMso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e2e26d2-5c39-427a-fe62-7ab4b5954326"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(1000,)\n",
            "\n",
            "Metrics (Fold 11):\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8289\n",
            "Recall: 0.9130\n",
            "F1 Score: 0.8690\n",
            "Confusion Matrix:\n",
            "[[18 13]\n",
            " [ 6 63]]\n",
            "\n",
            "Metrics (Fold 21):\n",
            "Accuracy: 0.7800\n",
            "Precision: 0.7812\n",
            "Recall: 0.8621\n",
            "F1 Score: 0.8197\n",
            "Confusion Matrix:\n",
            "[[28 14]\n",
            " [ 8 50]]\n",
            "\n",
            "Metrics (Fold 31):\n",
            "Accuracy: 0.8700\n",
            "Precision: 0.9062\n",
            "Recall: 0.8923\n",
            "F1 Score: 0.8992\n",
            "Confusion Matrix:\n",
            "[[29  6]\n",
            " [ 7 58]]\n",
            "\n",
            "Metrics (Fold 41):\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8507\n",
            "Recall: 0.8507\n",
            "F1 Score: 0.8507\n",
            "Confusion Matrix:\n",
            "[[23 10]\n",
            " [10 57]]\n",
            "\n",
            "Metrics (Fold 51):\n",
            "Accuracy: 0.9200\n",
            "Precision: 0.9189\n",
            "Recall: 0.9714\n",
            "F1 Score: 0.9444\n",
            "Confusion Matrix:\n",
            "[[24  6]\n",
            " [ 2 68]]\n",
            "\n",
            "Metrics (Fold 61):\n",
            "Accuracy: 0.8300\n",
            "Precision: 0.8243\n",
            "Recall: 0.9385\n",
            "F1 Score: 0.8777\n",
            "Confusion Matrix:\n",
            "[[22 13]\n",
            " [ 4 61]]\n",
            "\n",
            "Metrics (Fold 71):\n",
            "Accuracy: 0.8600\n",
            "Precision: 0.9310\n",
            "Recall: 0.8438\n",
            "F1 Score: 0.8852\n",
            "Confusion Matrix:\n",
            "[[32  4]\n",
            " [10 54]]\n",
            "\n",
            "Metrics (Fold 81):\n",
            "Accuracy: 0.7700\n",
            "Precision: 0.7826\n",
            "Recall: 0.8710\n",
            "F1 Score: 0.8244\n",
            "Confusion Matrix:\n",
            "[[23 15]\n",
            " [ 8 54]]\n",
            "\n",
            "Metrics (Fold 91):\n",
            "Accuracy: 0.7800\n",
            "Precision: 0.7368\n",
            "Recall: 0.9655\n",
            "F1 Score: 0.8358\n",
            "Confusion Matrix:\n",
            "[[22 20]\n",
            " [ 2 56]]\n",
            "\n",
            "Metrics (Fold 101):\n",
            "Accuracy: 0.7700\n",
            "Precision: 0.8429\n",
            "Recall: 0.8310\n",
            "F1 Score: 0.8369\n",
            "Confusion Matrix:\n",
            "[[18 11]\n",
            " [12 59]]\n",
            "\n",
            "Overall Metrics:\n",
            "Overall Accuracy: 0.8190\n",
            "Overall Precision: 0.8382\n",
            "Overall Recall: 0.8937\n",
            "Overall F1 Score: 0.8650\n",
            "\n",
            "Overall Confusion Matrix:\n",
            "[[239 112]\n",
            " [ 69 580]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#........Ensemble method with K-fold cross Validation and Results..........\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Generate Data for impleentation purposes\n",
        "X = df.iloc[:,:10]\n",
        "#print (X)\n",
        "X = X.to_numpy()\n",
        "print(X.shape)\n",
        "y = df['Class (Y/N)']\n",
        "#print (y)\n",
        "y = y.to_numpy()\n",
        "print(y.shape)\n",
        "X_new = X\n",
        "#print(X_new.shape)\n",
        "#print(X_new)\n",
        "\n",
        "# Define base classifiers for the ensemble\n",
        "ann_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC(probability=True, random_state=42)\n",
        "nb_classifier = GaussianNB()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "sgd_classifier = SGDClassifier(random_state=42)\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a majority voting ensemble classifier\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('ann', ann_classifier),\n",
        "        ('dt', dt_classifier),\n",
        "        ('svm', svm_classifier),\n",
        "        ('nb', nb_classifier),\n",
        "        ('knn', knn_classifier),\n",
        "        ('sgd', sgd_classifier),\n",
        "        ('rf', rf_classifier)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Initialize Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store overall metrics\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Perform Leave-One-Out cross-validation\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the ensemble model on the training data\n",
        "    ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = ensemble_classifier.predict(X_test)\n",
        "\n",
        "    # Append predictions and labels to the overall lists\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(y_test)\n",
        "\n",
        "    # Calculate metrics for each iteration\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # Calculate confusion matrix for each iteration\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Print metrics and confusion matrix for each iteration\n",
        "    print(f\"\\nMetrics (Iteration {len(all_predictions)}):\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "# Calculate the overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_precision = precision_score(all_labels, all_predictions)\n",
        "overall_recall = recall_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "# Calculate the overall confusion matrix\n",
        "overall_confusion_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Print overall metrics and confusion matrix\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "print(overall_confusion_matrix)\n"
      ],
      "metadata": {
        "id": "yp3yCED2qM5t",
        "outputId": "d913cd9d-36d3-4fdf-eb72-ad914992a50e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0d08bc5f42fd>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Generate Data for impleentation purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#print (X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9idT-W1zqaUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZLv1c4GdX4i08cbXsgnp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}